from pathlib import Path

readme_content = """# ğŸ§  Agentic RAG Chat System

This project is a user-facing, chat-style **Retrieval-Augmented Generation (RAG)** system using a **local LLM (Mistral via Ollama)**. The LLM can use tools like querying a MySQL database containing real-world government documents.

![Agentic RAG System Diagram](assets/agentic_rag_system.webp)

---

## ğŸš€ Features

- âœ… Local LLM (Mistral) via Ollama  
- âœ… Daily auto-updating data pipeline (Federal Register API)  
- âœ… Tool-calling Agentic LLM (uses custom tools)  
- âœ… MySQL-based document storage  
- âœ… FastAPI backend with Swagger + HTML UI  
- âœ… Clear logging, tool triggers, and debug-friendly  

---

## ğŸ§© Project Structure

chat_rag_project/
â”‚
â”œâ”€â”€ agent/ # LLM agent logic and tool calls
â”‚ â”œâ”€â”€ llm_agent.py
â”‚ â”œâ”€â”€ tool_schema.py
â”‚ â””â”€â”€ tools.py
â”‚
â”œâ”€â”€ api/ # FastAPI web server
â”‚ â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data_pipeline/ # Daily data fetch and clean
â”‚ â”œâ”€â”€ downloader.py
â”‚ â”œâ”€â”€ processor.py
â”‚ â””â”€â”€ run_pipeline.py
â”‚
â”œâ”€â”€ db/ # MySQL DB integration
â”‚ â”œâ”€â”€ insert_documents.py
â”‚ â”œâ”€â”€ mysql_setup.sql
â”‚ â””â”€â”€ query_tools.py
â”‚
â”œâ”€â”€ static/ # HTML UI (Bootstrap + JS)
â”‚ â””â”€â”€ index.html
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md



---

## âš™ï¸ How to Run

```bash
# Create and activate environment
conda create -n rag_env python=3.10 -y
conda activate rag_env

# Install required packages
pip install -r requirements.txt

# Setup MySQL database
mysql -u root -p < db/mysql_setup.sql

# Download + clean + store federal data
python -m data_pipeline.run_pipeline

# Start the FastAPI server
uvicorn api.main:app --reload

# Visit the HTML UI at:
# http://localhost:8000/static/index.html



ğŸ§ª Example Queries

    List 3 recent documents from Energy Department about clean energy

    Give me a summary of executive orders related to cybersecurity

    Any test procedure updates for central air conditioners?

ğŸ› ï¸ Notes

    LLM used: mistral from Ollama (http://localhost:11434)

    All database calls are async (aiomysql)

    Tool results are hidden from user unless returned via LLM

    You can replace Mistral with any tool-enabled model (e.g., qwen)

"""
# Write to file with UTF-8 encoding to handle emojis
Path("README.md").write_text(readme_content.strip(), encoding="utf-8")
print("âœ… README.md has been generated successfully!")